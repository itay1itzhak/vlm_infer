model:
  type: "local"
  max_new_tokens: 512
  temperature: 0.7
  top_p: 0.9
  is_chat_model: true
  torch_dtype: "float16"
  device_map: "auto" 